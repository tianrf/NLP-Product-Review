{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jieba\n",
    "import csv\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(pathfile,header=True):\n",
    "    phrase = []\n",
    "    label = []\n",
    "\n",
    "    with open (pathfile) as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile)\n",
    "\n",
    "        for row in csvReader:\n",
    "            phrase.append(row[0])\n",
    "            label.append(row[1])\n",
    "    if header:\n",
    "        X = np.asarray(phrase[1:])\n",
    "        Y = np.asarray(label[1:], dtype=int)\n",
    "    else:\n",
    "        X = np.asarray(phrase)\n",
    "        Y = np.asarray(label, dtype=int)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word2vec():\n",
    "    w2v_model = gensim.models.KeyedVectors.load(r'Tencent/Tencent_Word.bin', mmap='r')\n",
    "    w2v_model.index2entity[0]=' '\n",
    "    \n",
    "    word_embeddings=w2v_model.vectors.copy()\n",
    "    word_embeddings[0]=np.zeros(200)\n",
    "    word2vec=w2v_model\n",
    "    word2index={token: token_index for token_index, token in enumerate(w2v_model.index2word)}\n",
    "    return word_embeddings,word2vec,word2index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataPreprocess():\n",
    "    def __init__(self,word2index,max_len=100):\n",
    "        #get the csv file \n",
    "        self.dictionary=word2index\n",
    "        self.max_len=max_len\n",
    "    def cut_sentence(self,text):\n",
    "        if isinstance(text,str):\n",
    "            cut_list=[word  for word in jieba.lcut(text,cut_all=False) if word!=' ']\n",
    "        else:\n",
    "            cut_list=[jieba.lcut(sentence,cut_all=False) for sentence in text]\n",
    "            i=0\n",
    "            for i in range(len(cut_list)):\n",
    "                cut_list[i]=[word  for word in cut_list[i] if word!=' ']\n",
    "                i+=1\n",
    "            self.max_len=max([len(x) for x in cut_list])\n",
    "        return np.array(cut_list)\n",
    "    \n",
    "    def sentence2index(self,cut_list):\n",
    "            m=cut_list.shape[0]\n",
    "            X_indices=np.zeros((m,self.max_len),dtype=int)\n",
    "            for i in range(m):\n",
    "                j=0\n",
    "                for word in cut_list[i,]:\n",
    "                    try:\n",
    "                        X_indices[i,j]=self.dictionary[word]\n",
    "                    except:\n",
    "                        X_indices[i,j]=self.dictionary['unknown']\n",
    "                    j+=1\n",
    "            return X_indices\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
